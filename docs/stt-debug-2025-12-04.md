# Meeting STT / 요약 문제 디버깅 정리 (2025-12-04)

## 1. 증상 요약

- 브라우저에서 음성을 녹음 후 업로드했지만, STT 결과가 비어 있거나 "인식된 발화가 없습니다." 로만 나옴.
- 요약 결과도 항상 "인식된 발화가 없어 요약할 내용이 없습니다." 로 반환됨.
- 서버 로그 상으로는 `POST /meetings/record` 가 항상 `201 Created` 로 성공.
- 이후에는 Azure OpenAI 요약 호출 시 `content_filter` 로 인한 400 에러가 발생하여, API가 응답을 차단하는 경우도 확인.

## 2. 원인 분석

### 2.1 STT (Azure Speech) 결과가 항상 빈 문자열

#### 2.1.1 초기 구조

- 프론트엔드
  - `MediaRecorder` 로 브라우저에서 오디오를 녹음.
  - `Blob(chunks, { type: 'audio/webm' })` 으로 WebM(실제로는 Opus 코덱) 데이터를 생성.
  - `/meetings/record` 엔드포인트로 `FormData(audio=recording.webm, duration_seconds=...)` 전송.

- 백엔드 (`app/service/stt_service.py`)
  - Azure Speech REST API `conversation` 엔드포인트 호출.
  - `Content-Type: audio/webm` 또는 `audio/webm; codecs=opus` 로 설정.
  - 응답 예시:
    ```json
    {"RecognitionStatus":"Success","Offset":0,"Duration":200000000,"DisplayText":""}
    ```
  - `RecognitionStatus` 가 `Success` 인데도 `DisplayText` 가 항상 빈 문자열로 옴.

#### 2.1.2 디버깅 포인트

- 브라우저 콘솔 로그 추가 (`app/static/js/recorder.js`)
  - 업로드 전:
    - `[Meeting-STT] blob size(bytes)= ... durationSeconds= ...`
  - 서버 응답 후:
    - `[Meeting-STT] 서버 인식 결과 transcript: ...`
    - `[Meeting-STT] 서버 요약 결과 summary: ...`

- 서버 로그 추가 (`stt_service.py`)
  - `DisplayText == ""` 인 경우:
    - `[STT] Azure Speech returned empty text. raw: { ... }`

- 결과
  - 브라우저에서 녹음한 blob 크기와 길이는 정상(수십~수백 KB, 수 초 길이).
  - Azure Speech 응답은 HTTP 200 + `RecognitionStatus: Success` 이지만 `DisplayText` 가 항상 빈 문자열.
  - 즉, MediaRecorder + WebM/Opus 조합을 Azure Speech REST API가 제대로 처리하지 못하는 것으로 판단.

### 2.2 Web Audio API + WAV(PCM) 로 변경 후 정상 동작

#### 2.2.1 프론트엔드 변경 (`app/static/js/recorder.js`)

- 기존:
  - `MediaRecorder(stream)` → `audio/webm` Blob 생성 후 업로드.

- 변경 후:
  - Web Audio API (`AudioContext`, `createMediaStreamSource`, `createScriptProcessor`) 사용.
  - `onaudioprocess` 에서 1채널 PCM(`Float32Array`)을 매 샘플마다 수집.
  - 수집된 PCM 데이터를 직접 16-bit mono WAV 포맷으로 인코딩:
    - `RIFF`/`WAVE` 헤더 작성.
    - `BitsPerSample = 16`, `NumChannels = 1`, `SampleRate = audioContext.sampleRate`.
    - `float32` → 16-bit PCM 으로 변환 후 DataView 에 기록.
  - 최종적으로 `Blob([...], { type: 'audio/wav' })` 생성.
  - `/meetings/record` 로 `recording.wav` 업로드.

- 업로드 시 여전히 다음 로그를 찍어 디버깅 유지:
  - `[Meeting-STT] blob size(bytes)= ... durationSeconds= ...`
  - `[Meeting-STT] 서버 인식 결과 transcript: ...`
  - `[Meeting-STT] 서버 요약 결과 summary: ...`

#### 2.2.2 백엔드 변경 (`app/service/stt_service.py`)

- Azure Speech 호출 헤더 변경:

  ```python
  headers = {
      "Ocp-Apim-Subscription-Key": settings.azure_speech_key,
      # 프런트엔드에서 업로드하는 WAV(PCM) 포맷에 맞춰 Content-Type 설정
      "Content-Type": "audio/wav",
      "Accept": "application/json",
  }
  ```

- `DisplayText == ""` 일 때 raw 응답 로그 출력은 유지.

- 이 조합 이후에는 Azure Speech 가 제대로 텍스트를 반환하며, STT → 요약 전체 플로우가 정상 동작하는 것을 확인.

### 2.3 Azure OpenAI 요약 단계의 Content Filter 에러

- STT 이후, 요약을 담당하는 `summary_service.summarize_meeting` 에서 LangChain + Azure OpenAI 호출.
- 특정 내용(성 관련 발화 등)인 경우, Azure OpenAI 가 정책상 응답을 차단:

  - 에러 예시:
    ```json
    {
      "error": {
        "message": "The response was filtered due to the prompt triggering Azure OpenAI's content management policy...",
        "code": "content_filter",
        "innererror": {
          "code": "ResponsibleAIPolicyViolation",
          "content_filter_result": {
            "sexual": {"filtered": true, "severity": "medium"}
          }
        }
      }
    }
    ```

- 현재 코드는 이 예외를 전부 묶어서 502로 변환:

  ```python
  raise HTTPException(
      status_code=status.HTTP_502_BAD_GATEWAY,
      detail=f"Azure OpenAI 요약 호출 실패: {exc}",
  )
  ```

- 결과적으로 클라이언트에서는 `502` 와 함께 긴 content_filter 관련 에러 메시지를 보게 됨.

## 3. 최종 해결 상태

1. **STT 인식 문제**
   - 원인: MediaRecorder(WebM/Opus) + Azure Speech REST API 조합에서 `DisplayText` 가 항상 빈 문자열.
   - 해결: Web Audio API 를 사용해 PCM을 직접 수집하고, 16-bit mono WAV 로 인코딩하여 `audio/wav` 로 Azure Speech 에 전송.
   - 현재: STT → transcript 생성까지 정상 동작.

2. **요약(Content Filter) 문제**
   - 원인: Azure OpenAI 정책상, 특정 내용(예: 성 관련 발화)이 포함된 경우 content filter 가 동작, 응답이 차단됨.
   - 현재: 예외가 502로 래핑되어 클라이언트에 노출.
   - 아직 적용하지 않은 개선 아이디어:
     - content_filter (`ResponsibleAIPolicyViolation`) 인 경우만 따로 400 으로 분리하여 사용자에게 "정책상 요약 불가" 메시지를 간단히 전달.
     - 또는 요약만 비워 두고, 회의 기록은 그대로 저장하는 폴백 로직 추가.

## 4. 향후 개선 아이디어

1. **STT 백엔드 다양화/폴백**
   - 현재는 Azure Speech → (옵션으로) 외부 Whisper API.
   - Whisper API 를 활성화하고, Azure Speech 실패 시 Whisper 로 폴백하는 전략 고려.

2. **요약 Content Filter 처리 개선**
   - `summary_service.py` 에서 Azure OpenAI 예외 메시지를 파싱해 `content_filter` 인 경우만 400 으로 분리.
   - 프론트엔드에서 400 응답을 받아 "정책상 자동 요약을 제공할 수 없습니다." 같은 짧은 안내 문구 표시.
   - 민감한 도메인(성교육, 폭력예방 교육 등)에서는 시스템 프롬프트에 "전문적/교육적 맥락"임을 명시해서 불필요한 차단을 줄이는 것도 검토.

3. **로그/모니터링 정리**
   - 현재 STT/요약 관련 디버그 로그가 콘솔/터미널에 출력되고 있음.
   - 운영 환경에서는 적절한 로깅 레벨/마스킹을 적용해 민감한 내용이 로그에 과도하게 남지 않도록 조정 필요.
